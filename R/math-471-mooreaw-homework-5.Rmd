---
output: pdf_document
---

```{r opts, include = FALSE}
knitr::opts_chunk$set(
  warning = FALSE, message = FALSE, echo = FALSE,
  fig.align = "center", fig.width = 5, fig.height = 4
)
```

```{r init, echo = FALSE}
library(tidyverse)
library(patchwork)
library(knitr)

theme_set(
  theme_minimal(base_size = 15) +
    theme(panel.grid.minor = element_blank())
)
```

# Andrew Moore, `r format(Sys.Date(), "%m/%d/%Y")`

## MATH-471, Homework 5

<!-- 5.16-(a), 5.18, 5.21-(a), 5.28-(a), (b), and (d), 5.32, 5.34, 5.36, 5.37, 5.39, 5.42 -->

### 5.16

A study is designed to test the hypotheses $H_0: \mu \geq 26$ versus $H_a: \mu < 26$. A random sample of 50 units was selected from a specified population, and the measurements were summarized to $\bar{y} = 25.9$ and $s = 7.6$.

---

**a.**  With $\alpha = .05$, is there substantial evidence that the population mean is less than 26?

We have a sample of 50 units. We will compute the test statistic, $TS = \frac{\bar{y} - \mu_0}{s / \sqrt{n}}$. Using the t-distribution to calculate the p-value, we have:

```{r, echo = TRUE}
n  <- 50
s  <- 7.6
y  <- 25.9
m0 <- 26
ts <- (y - m0) / (s / sqrt(n))

# probability of seeing this or a more extreme (smaller) value, if h0 is true
(p <- pt(ts, n - 1))
```

The p-value, `r round(p, 3)`, is larger than our $\alpha$. This means we fail to reject $H_0$, and cannot conclude that the population mean is less than 26.

\newpage
### 5.18

Refer to Exercise 5.16. Graph the power curve for rejecting $H_0: \mu < 26$ for the following values of $\mu$: 20, 21, 22, 23, 24, 25, and 26.

---

```{r q518}
pwr <- function(n, s, m0, m1, a, one_tail = TRUE) {
  if (one_tail) z_a <- qnorm(1 - a) else z_a <- qnorm(1 - a/2)
  
  ts <- abs(m1 - m0) / (s / sqrt(n))
  
  1 - pnorm(z_a - ts)
}

n  <- 50
s  <- 7.6
m0 <- 26
m1 <- 20:26
a  <- 0.05

q518 <- tibble(x = m1, y = pwr(n, s, m0, m1, a))

ggplot(q518, aes(x = x, y = y)) +
  geom_line(color = "orange") +
  geom_point(color = "orange") +
  scale_y_continuous(breaks = seq(0, 1, .2)) +
  labs(x = expression(mu), y = expression(1 - beta))
```

**a.** Describe the change in the power as the value of $\mu$ decreases from $\mu_0 = 26$.

Power increases dramatically between $\mu = 25$ to $\mu = 23$, reaching over 90%+ when $\mu \leq 22$.

**b.** Suppose the value of $n$ remains at 50 but $\alpha$ is decreased to $\alpha = .01$. Without recalculating the values of the power, superimpose on the graph for $\alpha = .05$ and $n = 50$ the power curve for $\alpha = .01$ and $n = 50$.

```{r q518b}
q518b <- bind_rows(
  "0.05" = q518,
  "0.01" = tibble(x = m1, y = pwr(n, s, m0, m1, 0.01)),
  .id = "alpha"
)

ggplot(q518b, aes(x = x, y = y, color = alpha)) +
  geom_line() +
  geom_point() +
  scale_color_manual(name = expression(alpha), values = c("grey", "orange")) +
  scale_y_continuous(breaks = seq(0, 1, .2)) +
  labs(x = expression(mu), y = expression(1 - beta)) +
  theme(legend.position = "top")
```

**c.** Suppose the value of $n$ is decreased to 35 but $\alpha$ is kept at $\alpha = .05$. Without recalculating the values of the power, superimpose on the graph for $\alpha = .05$ and $n = 50$ the power curve for $\alpha = .05$ and $n = 35$.

```{r q518c}
q518c <- bind_rows(
  "50" = q518,
  "35" = tibble(x = m1, y = pwr(35, s, m0, m1, a)),
  .id = "n"
)

ggplot(q518c, aes(x = x, y = y, color = n)) +
  geom_line() +
  geom_point() +
  scale_color_manual(name = "N", values = c("grey", "orange")) +
  scale_y_continuous(breaks = seq(0, 1, .2)) +
  labs(x = expression(mu), y = expression(1 - beta)) +
  theme(legend.position = "top")
```

\newpage
### 5.21

A study was conducted of 90 adult male patients following a new treatment for congestive heart failure. One of the variables measured on the patients was the increase in exercise capacity (in minutes) over a 4-week treatment period. The previous treatment regime had produced an average increase of $\mu = 2$ minutes. The researchers wanted to evaluate whether the new treatment had increased the value of $\mu$ in comparison to the previous treatment. The data yielded $\bar{y} = 2.17$ and $s = 1.05$.

---

**a.** Using $\alpha = .05$, what conclusions can you draw about the research hypothesis?

```{r q521}
a  <- 0.05
n  <- 90
s  <- 1.05
m1 <- 2.17
m0 <- 2
ts <- (m1 - m0) / (s / sqrt(n))
p  <- 1 - pnorm(ts)
```

Based on the study information, we should conduct a one-tailed hypothesis test. Our null hypothesis is $H_0: \mu \leq 2$, and our alternative hypothesis is $H_1: \mu > 2$. Given that the sample size is large (n = 90), we can apply the central limit theorem when considering the distribution of the mean. Computing the test statistic, we receive `r round(ts, 3)`, which is associated with a *p* value of `r round(p, 3)` (larger than our $\alpha$ of 0.05). Based on these results, we do not have sufficient evidence to reject $H_0$, and cannot conclude that the new treatment regime results in an improvement compared to the existing treatment. 

\newpage
### 5.28

The R&D department of a paint company has developed an additive that it hopes will in crease the ability of the company's stain for outdoor decks to resist water absorption. The current formulation of the stain has a mean absorption rate of 35 units. Before changing the stain, a study was designed to evaluate whether the mean absorption rate of the stain with the additive was decreased from the current rate of 35 units. The stain with the additive was applied to 50 pieces of decking material. The resulting data were summarized to $\bar{y} = 33.6$ and $s = 9.2$

---

**a.** Is there substantial evidence $(\alpha =  .01)$ that the additive reduces the mean absorption from its current value?

```{r q528a}
a  <- 0.01
n  <- 50
s  <- 9.2
m1 <- 33.6
m0 <- 35
ts <- (m1 - m0) / (s / sqrt(n))
p  <- pnorm(ts)
```

Based on the study information, we should conduct a one-tailed hypothesis test. Our null hypothesis is $H_0: \mu \geq$ `r m0`, and our alternative hypothesis is $H_1: \mu <$ `r m0`. Given that the sample size is large (n = `r n`), we can apply the central limit theorem when considering the distribution of the mean. Computing the test statistic, we receive `r round(ts, 3)`, which is associated with a *p* value of `r round(p, 3)` (larger than our $\alpha$ of `r a`). Alternatively, we can examine the Z-value for our alpha level: `r round(qnorm(0.01), 3)`. Our computed test-statistic is not as extreme as our threshold. Based on these results, we do not have sufficient evidence to reject $H_0$, and cannot conclude that the additive decreases the absorption rate.

**b.** What is the level of significance (p-value) of your test results?

The significance level is `r round(p, 3)`.

**d.** Estimate the mean absorption using a 99% confidence interval. Is the confidence interval consistent with your conclusions from the test of hypotheses?

```{r q528d}
moe <- qnorm(1 - a/2) * s / sqrt(n)
ci <- m1 + (c(-1, 1) * moe)
ci_fmt <- str_c("[", round(ci, 2)[1], ", ", round(ci, 2)[2], "]")
```

A 99% confidence interval for the sample mean is `r ci_fmt`. The confidence interval is consistent with our hypothesis test. Specifically, the interval contains the value of $\mu_0$, 35.

\newpage
### 5.32

A tobacco company advertises that the average nicotine content of its cigarettes is at most 14 milligrams. A consumer protection agency wants to determine whether the average nicotine content is in fact greater than 14. A random sample of 300 cigarettes of the company's brand yields an average nicotine content of 14.6 milligrams and a standard deviation of 3.8 milligrams. Determine the level of significance of the statistical test of the agency's claim that $\mu$ is greater than 14. If $\alpha = .01$, is there significant evidence that the agency's claim has been supported by the data?

---

```{r q532}
a  <- 0.01
n  <- 300
s  <- 3.8
m1 <- 14.6
m0 <- 14
ts <- (m1 - m0) / (s / sqrt(n))
p  <- 1 - pnorm(ts)
```

Based on the study information, we should conduct a one-tailed hypothesis test. Our null hypothesis is $H_0: \mu \leq$ `r m0`, and our alternative hypothesis is $H_1: \mu >$ `r m0`. Given that the sample size is large (n = `r n`), we can apply the central limit theorem when considering the distribution of the mean. Computing the test statistic, we receive `r round(ts, 3)`, which is associated with a *p* value of `r round(p, 3)` (smaller than our $\alpha$ of `r a`). Alternatively, we can examine the Z-value for our alpha level: `r round(qnorm(0.99), 3)`. Our computed test-statistic is more extreme than our threshold (i.e., it is larger). Based on these results, we have sufficient evidence to reject $H_0$, concluding that the hypothesis that $\mu \leq 14$ is inconsistent with the collected data.

\newpage
### 5.34

Provide the rejection region based on a t-test statistic for the following situations: 

- **a.** $H_0: \mu \geq 28$ versus $H_a: \mu < 28$ with $n = 11$, $\alpha = .05$

- **b.** $H_0: \mu \leq 28$ versus $H_a: \mu > 28$ with $n = 21$, $\alpha = .025$

- **c.** $H_0: \mu \geq 28$ versus $H_a: \mu < 28$ with $n = 8$, $\alpha = .001$

- **d.** $H_0: \mu = 28$ versus $H_a: \mu \neq 28$ with $n = 13$, $\alpha = .01$

---

The shaded area of each plot denote the rejection regions.

```{r, fig.width=6, fig.height=6.5}
q534 <- tibble(
  `a` = qt(0.05, 11 - 1),
  `b` = qt(0.025, 21 - 1, lower.tail = FALSE),
  `c` = qt(0.001, 8 - 1),
  `d` = qt(1 - 0.01/2, 13 - 1)
)

p_a <- ggplot(tibble(x = c(-5, 5)), aes(x)) +
  stat_function(fun = dt, args = lst(df = 10)) +
  stat_function(fun = dt, xlim = c(-5, q534$a), geom = "area", args = lst(df = 10)) +
  labs(x = "t", y = "", title = "a. t < -1.81") +
  theme(axis.text.y = element_blank())

p_b <- ggplot(tibble(x = c(-5, 5)), aes(x)) +
  stat_function(fun = dt, args = lst(df = 20)) +
  stat_function(fun = dt, xlim = c(q534$b, 5), geom = "area", args = lst(df = 20)) +
  labs(x = "t", y = "", title = "b. t > 2.09") +
  theme(axis.text.y = element_blank())

p_c <- ggplot(tibble(x = c(-5, -3)), aes(x)) +
  stat_function(fun = dt, args = lst(df = 7)) +
  stat_function(fun = dt, xlim = c(-7, q534$c), geom = "area", args = lst(df = 7)) +
  labs(x = "t", y = "", title = "c. t < -4.79") +
  theme(axis.text.y = element_blank())

p_d <- ggplot(tibble(x = c(-5, 5)), aes(x)) +
  stat_function(fun = dt, args = lst(df = 12)) +
  stat_function(fun = dt, xlim = c(-5, -q534$d), geom = "area", args = lst(df = 12)) +
  stat_function(fun = dt, xlim = c(q534$d, 5), geom = "area", args = lst(df = 12)) +
  labs(x = "t", y = "", title = "d. t < -3.05 or t > 3.05") +
  theme(axis.text.y = element_blank())

(p_a + p_b) / (p_c + p_d)
```

\newpage
### 5.36

The ability to read rapidly and simultaneously maintain a high level of comprehension is often a determining factor in the academic success of many high school students. A school district is considering a supplemental reading program for incoming freshmen. Prior to implementing the program, the school runs a pilot program on a random sample of $n = 20$ students. The students were thoroughly tested to determine reading speed and reading comprehension. Based on a fixed-length standardized test reading passage, the following reading times (in minutes) and comprehension scores (based on a 100-point scale) were recorded.

---

```{r, echo = FALSE}
q536 <- tibble(
  student = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20),
  reading_time = c(5, 7, 15, 12, 8, 7, 10, 11, 9, 13, 10, 6, 11, 8, 10, 8, 7, 6, 11, 8),
  comprehension = c(60, 76, 76, 90, 81, 75, 95, 98, 88, 73, 90, 66, 91, 83, 100, 85, 76, 69, 91, 78)
)
```

```{r, echo = FALSE}
q536_ss <- q536 %>%
  pivot_longer(-student) %>%
  group_by(name) %>%
  summarise(n = n(), m = mean(value), s = sd(value)) %>%
  mutate(across(m:s, round, 2))
```

**a.** What is the population about which inferences are being made?

Incoming freshmen at the school district.

**b.** Place a 95% confidence interval on the mean reading time for all incoming freshmen in the district.

```{r}
y <- mean(q536$reading_time)
s <- sd(q536$reading_time)
n <- nrow(q536)
a <- 0.05

tval <- qt(1 - a/2, n - 1)

moe <- tval * s / sqrt(n)

(ci <- y + (c(-1, 1) * moe))
```

**c.** Plot the reading time using a normal probability plot or boxplot. Do the data appear to be a random sample from a population having a normal distribution?

```{r}
ggplot(q536, aes(sample = reading_time)) +
  geom_qq_line(lty = "dashed") +
  geom_qq(color = "orange")
```

The data do appear to increase consistently around the identity line, however, the data exhibit a step-like pattern. This is because the reading times are in whole minutes (integers); ignoring this fact, I would say the data appear normal.

**d.** Provide an interpretation of the interval estimate in part (b).

With 95% confidence, the average reading time for incoming freshmen is between 7.9 and 10.3 minutes. If we were to repeat the study 100 times, 95 of the similarly constructed intervals would contain the true mean.

\newpage
### 5.37

Refer to Exercise 5.36. Using the reading comprehension data, is there significant evidence that the reading program would produce for incoming freshmen a mean comprehension score greater than 80, the statewide average for comparable students during the previous year? Determine the level of significance for your test. Interpret your findings.

---

```{r}
q537 <- q536 %>%
  summarise(
    n  = n(),
    y  = mean(comprehension),
    s  = sd(comprehension),
    ts = (y - 80) / (s / sqrt(n)),
    p  = pt(ts, n - 1)
  )

ggplot(q536, aes(sample = comprehension)) +
  geom_qq_line(lty = "dashed") +
  geom_qq(color = "orange")
```

Examining the comprehension data, we have a generally linear relationship observed in the QQ-plot. This question can be answered using a one-tailed hypothesis test ($H_0: \mu \leq 80$ vs. $H_1: \mu > 80$). Given that our sample-size is below 30, and given that our data appear to come from a normal distribution, we will rely on the T-distribution for our test statistic.

Computing the test statistic, we receive `r round(q537$ts, 3)`, which is associated with a *p* value (significance level) of `r round(q537$p, 3)`. This indicates we cannot reject $H_0$. Our observed data is consistent with a $\mu \leq 80$.

\newpage
### 5.39

A consumer testing agency wants to evaluate the claim made by a manufacturer of discount tires. The manufacturer claims that its tires can be driven at least 35,000 miles before wearing out. To determine the average number of miles that can be obtained from the manufacturer's tires, the agency randomly selects 60 tires from the manufacturer's warehouse and places the tires on 15 cars driven by test drivers on a 2-mile oval track. The number of miles driven (in thousands of miles) until the tires are determined to be worn out is given in the following table.

---

```{r, echo = FALSE}
q539 <- tibble(
  car = 1:15,
  mi  = c(25, 27, 35, 42, 28, 37, 40, 31, 29, 33, 30, 26, 31, 28, 30)
)

mi <- rep(q539$mi, 4)
```

**a.** Place a 99% confidence interval on the average number of miles driven, $\mu$, prior to the tires wearing out.

```{r}
a <- 0.01
n <- 60
m <- mean(mi)
s <- sd(mi)
z <- qnorm(1 - a)
e <- z * s / sqrt(n)  # MoE

ci <- m + (c(-1, 1) * e)
ci_fmt <- str_c("[", round(ci, 2)[1], ", ", round(ci, 2)[2], "]")
```

For this study, I assume the total sample size is 60, and that we can apply the central limit theorem when estimating the unknown population mean. With an alpha value of `r a`, this corresponds to a Z-value of `r round(z, 3)`. Our sample mean is `r round(m, 2)`, with a standard deviation of `r round(s, 2)`, resulting in a confidence interval of `r ci_fmt`.

**b.** Is there significant evidence ($\alpha = .01$) that the manufacturer's claim is false? What is the level of significance of your test? Interpret your findings.

```{r}
m1 <- m
m0 <- 35
ts <- (m1 - m0) / (s / sqrt(n))
p  <- pnorm(ts)
```

Our confidence interval excludes 35,000 miles, which should provide the same inference as a two-sided test ($H_0: \mu = 35$ vs. $H_1: \mu \neq 35$) in which we reject $H_0$. However, for part **b.**, we are asked to test the specific claim that $\mu < 35$. This is a one-sided hypothesis test ($H_0: \mu \geq 35$ vs. $H_1: \mu < 35$). As with part **a.** we will apply the central limit theorem when considering the mean's distribution. Computing the test statistic, we receive `r round(ts, 3)`, which is associated with a *p* value of `r p` (much smaller than our $\alpha$ of `r a`). Based on these results, we would reject $H_0$, concluding that it is inconsistent to claim that the tires can last at least 35,000 miles based on our observed data.

\newpage
### 5.42

A dealer in recycled paper places empty trailers at various sites. The trailers are gradually filled by individuals who bring in old newspapers and magazines and are picked up on several schedules. One such schedule involves pickup every second week. This schedule is desirable if the average amount of recycled paper is more than 1,600 cubic feet per 2-week period. The dealer's records for 18 2-week periods show the following volumes (in cubic feet) at a particular site:

```{r}
(v <- c(1660, 1820, 1590, 1440, 1730, 1680, 1750, 1720, 1900, 1570, 1700, 1900, 1800, 1770, 2010, 1580, 1620, 1690))
```

$\bar{y}$ = `r round(mean(v), 1)` and *s* = `r round(sd(v), 1)`.

---

**a.** Assuming the 18 2-week periods are fairly typical of the volumes throughout the year, is there significant evidence that the average volume $\mu$ is greater than 1,600 cubic feet?

Our sample size is 18. We will use a QQ-plot to investigate whether we can reasonably assume the data come from a normal distribution.

```{r}
ggplot(tibble(v), aes(sample = v)) +
  geom_qq_line(lty = "dashed") +
  geom_qq(color = "orange")

qq <- qqnorm(v, plot.it = FALSE)
```

Based on the plot, it seems appropriate to assume the data come from a normal distribution. The correlation between the data and normal distribution quantile values is also very strong (*r* = `r round(with(qq, cor(x, y)), 3)`).

```{r}
a <- 0.05
n <- length(v)
m <- mean(v)
s <- sd(v)
m0 <- 1600

t_0 <- qt(1 - a, n - 1)
t_1 <- (m - m0) / (s / sqrt(n))
```

We will answer this question using a one-sided test ($H_0: \mu \leq 1600$ vs. $H_1: \mu > 1600$), with an $\alpha$ of 0.05. Given that our sample size is below 30, we cannot apply the central limit theorem, and will instead rely on the T-distribution. Computing the test statistic, we receive `r round(t_1, 3)`, which is larger than $T_{0.95, d.f.=17}$ =  `r round(t_0, 3)`. Based on our $\alpha$, we would reject $H_0$, concluding that a $\mu \leq 1600$ is inconsistent with our observed data.

**b.** Place a 95% confidence interval on $\mu$.

```{r}
tval <- qt(1 - a/2, n - 1)
moe  <- tval * s / sqrt(n)

(ci <- m + (c(-1, 1) * moe))
```

**c.** Compute the p-value for the test statistic. Is there strong evidence that $\mu$ is greater than 1,600?

For the one-sided test performed in **a.**, the *p*-value is `r round(1 - pt(t_1, n - 1), 3)`. This is strong evidence that $\mu > 1600$.
